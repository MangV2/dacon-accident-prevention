{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minkyu\\AppData\\Local\\anaconda3\\envs\\sd2\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:195: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v4 of SentenceTransformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pandas as pd\n",
    "\n",
    "# Embedding Vector 추출에 활용할 모델(jhgan/ko-sbert-sts) 불러오기\n",
    "model = SentenceTransformer('jhgan/ko-sbert-sts', use_auth_token=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train_df.csv', encoding = 'utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['공사종류(대분류)'] = df['공사종류'].str.split(' / ').str[0]\n",
    "df['공사종류(중분류)'] = df['공사종류'].str.split(' / ').str[1]\n",
    "df['공종(대분류)'] = df['공종'].str.split(' > ').str[0]\n",
    "df['공종(중분류)'] = df['공종'].str.split(' > ').str[1]\n",
    "df['사고객체(대분류)'] = df['사고객체'].str.split(' > ').str[0]\n",
    "df['사고객체(중분류)'] = df['사고객체'].str.split(' > ').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "공종(중분류)\n",
       "철근콘크리트공사        6353\n",
       "가설공사            2268\n",
       "기타              1859\n",
       "해체 및 철거공사        933\n",
       "기계설비공사           845\n",
       "토공사              816\n",
       "철골공사             703\n",
       "건축물 부대공사         581\n",
       "수장공사             534\n",
       "관공사              497\n",
       "건축 토공사           496\n",
       "미장공사             482\n",
       "전기설비공사           456\n",
       "타일 및 돌공사         404\n",
       "도로 및 포장공사        362\n",
       "교량공사             310\n",
       "조적공사             297\n",
       "도장공사             266\n",
       "터널공사             259\n",
       "산업설비공사           256\n",
       "목공사              247\n",
       "금속공사             239\n",
       "창호 및 유리공사        218\n",
       "하천공사             203\n",
       "방수공사             190\n",
       "관공사 부대공사         177\n",
       "항만공사             148\n",
       "지붕 및 홈통공사        144\n",
       "말뚝공사             106\n",
       "철도 및 궤도공사        104\n",
       "지정공사              86\n",
       "조경공사              58\n",
       "지반개량공사            45\n",
       "강구조물공사            41\n",
       "지반조사              33\n",
       "프리캐스트 콘크리트공사      19\n",
       "댐 및 제방공사          17\n",
       "특수 건축물공사           9\n",
       "통신설비공사             8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts('공종(중분류)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   공종(중분류)     평균유사도\n",
      "0      가시설  0.550008\n",
      "1     건설공구  0.540466\n",
      "2     건설기계  0.536110\n",
      "3     건설자재  0.541783\n",
      "4       기타  0.514122\n",
      "5       부재  0.526603\n",
      "6      시설물  0.536595\n",
      "7       질병  0.486281\n",
      "8  토사 및 암반  0.525183\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "grouped = df.groupby(\"사고객체(대분류)\")\n",
    "# 결과 저장을 위한 딕셔너리\n",
    "avg_similarities = {}\n",
    "\n",
    "# 각 그룹에 대해 평균 코사인 유사도 계산\n",
    "for category, group in grouped:\n",
    "    sentences = group['재발방지대책 및 향후조치계획'].tolist()\n",
    "    \n",
    "    # 그룹 내 문장이 2개 미만이면 계산할 수 없으므로 0 또는 np.nan 처리\n",
    "    if len(sentences) < 2:\n",
    "        avg_similarities[category] = np.nan\n",
    "        continue\n",
    "    \n",
    "    embeddings = model.encode(sentences, convert_to_tensor=False)\n",
    "    \n",
    "    sim_matrix = cosine_similarity(embeddings)\n",
    "    \n",
    "    # 대각선은 자기 자신과의 유사도로 제외 (k=1부터 시작)\n",
    "    n = sim_matrix.shape[0]\n",
    "    upper_tri_indices = np.triu_indices(n, k=1)\n",
    "    pairwise_sims = sim_matrix[upper_tri_indices]\n",
    "    \n",
    "    avg_similarity = np.mean(pairwise_sims)\n",
    "    avg_similarities[category] = avg_similarity\n",
    "\n",
    "# 결과 DataFrame 생성\n",
    "result_df = pd.DataFrame(list(avg_similarities.items()), columns=['공종(중분류)', '평균유사도'])\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 평균 유사도: 0.5285723\n"
     ]
    }
   ],
   "source": [
    "overall_avg = np.nanmean(list(avg_similarities.values()))\n",
    "print(\"전체 평균 유사도:\", overall_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     avg_similarities[category] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m sim_matrix \u001b[38;5;241m=\u001b[39m cosine_similarity(embeddings)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 대각선은 자기 자신과의 유사도로 제외 (k=1부터 시작)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\minkyu\\AppData\\Local\\anaconda3\\envs\\sd2\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:652\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    650\u001b[0m             \u001b[38;5;66;03m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[0;32m    651\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m convert_to_numpy:\n\u001b[1;32m--> 652\u001b[0m                 embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    654\u001b[0m         all_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n\u001b[0;32m    656\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [all_embeddings[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(length_sorted_idx)]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "grouped = df.groupby(\"공사종류(대분류)\")\n",
    "# 결과 저장을 위한 딕셔너리\n",
    "avg_similarities = {}\n",
    "\n",
    "# 각 그룹에 대해 평균 코사인 유사도 계산\n",
    "for category, group in grouped:\n",
    "    sentences = group['재발방지대책 및 향후조치계획'].tolist()\n",
    "    \n",
    "    # 그룹 내 문장이 2개 미만이면 계산할 수 없으므로 0 또는 np.nan 처리\n",
    "    if len(sentences) < 2:\n",
    "        avg_similarities[category] = np.nan\n",
    "        continue\n",
    "    \n",
    "    embeddings = model.encode(sentences, convert_to_tensor=False)\n",
    "    \n",
    "    sim_matrix = cosine_similarity(embeddings)\n",
    "    \n",
    "    # 대각선은 자기 자신과의 유사도로 제외 (k=1부터 시작)\n",
    "    n = sim_matrix.shape[0]\n",
    "    upper_tri_indices = np.triu_indices(n, k=1)\n",
    "    pairwise_sims = sim_matrix[upper_tri_indices]\n",
    "    \n",
    "    avg_similarity = np.mean(pairwise_sims)\n",
    "    avg_similarities[category] = avg_similarity\n",
    "\n",
    "# 결과 DataFrame 생성\n",
    "result_df = pd.DataFrame(list(avg_similarities.items()), columns=['공사종류(대분류)', '평균유사도'])\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 평균 유사도: 0.53173584\n"
     ]
    }
   ],
   "source": [
    "overall_avg = np.nanmean(list(avg_similarities.values()))\n",
    "print(\"전체 평균 유사도:\", overall_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
