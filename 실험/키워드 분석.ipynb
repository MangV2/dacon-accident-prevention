{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/minkyu/Desktop/open/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv(\"output2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['공사종류(대분류)'] = df['공사종류'].str.split(' / ').str[0]\n",
    "df['공사종류(중분류)'] = df['공사종류'].str.split(' / ').str[1]\n",
    "df['공종(대분류)'] = df['공종'].str.split(' > ').str[0]\n",
    "df['공종(중분류)'] = df['공종'].str.split(' > ').str[1]\n",
    "df['사고객체(대분류)'] = df['사고객체'].str.split(' > ').str[0]\n",
    "df['사고객체(중분류)'] = df['사고객체'].str.split(' > ').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model_name = \"jhgan/ko-sbert-sts\"\n",
    "embedding = SentenceTransformer(embedding_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from konlpy.tag import Okt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "# 한글 명사 추출을 위한 함수 정의 (필요에 따라 다른 토큰화 방법을 사용할 수 있음)\n",
    "def tokenize_korean(text):\n",
    "    return okt.nouns(text)\n",
    "\n",
    "# '인적사고' 별로 '재발방지대책 및 향후조치계획' 텍스트를 하나로 합치기\n",
    "grouped_text = df.groupby('인적사고')['재발방지대책 및 향후조치계획'].apply(lambda texts: ' '.join(texts))\n",
    "\n",
    "# 각 그룹에 대해 단어 빈도 계산\n",
    "result = {}\n",
    "for accident, text in grouped_text.items():\n",
    "    tokens = tokenize_korean(text)\n",
    "    freq = Counter(tokens)\n",
    "    # 빈도 상위 10개 단어 출력 (원하는 개수로 조정 가능)\n",
    "    common_words = freq.most_common(10)\n",
    "    result[accident] = common_words\n",
    "    print(f\"인적사고: {accident} - {sum(df['인적사고']==accident)}\")\n",
    "    print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 명사 추출을 위한 함수\n",
    "def tokenize_korean(text):\n",
    "    return okt.nouns(text)\n",
    "\n",
    "# (1) 사고원인 열을 모두 하나의 문자열로 합치기\n",
    "#     df['사고원인']이 NaN(결측치)일 수 있으니, astype(str)로 변환\n",
    "all_causes_text = ' '.join(df['사고원인'].astype(str).tolist())\n",
    "\n",
    "# (2) 전체 텍스트를 명사 단위로 토큰화\n",
    "tokens = tokenize_korean(all_causes_text)\n",
    "\n",
    "# (3) 토큰 빈도 계산\n",
    "freq = Counter(tokens)\n",
    "\n",
    "# (4) 빈도 상위 10개 단어 출력\n",
    "common_words = freq.most_common(10)\n",
    "print(\"사고원인 전체 텍스트에서 빈도 상위 10개 단어:\")\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "# 한글 명사 추출을 위한 함수 정의 (필요에 따라 다른 토큰화 방법을 사용할 수 있음)\n",
    "def tokenize_korean(text):\n",
    "    return text.split()\n",
    "\n",
    "# '인적사고' 별로 '재발방지대책 및 향후조치계획' 텍스트를 하나로 합치기\n",
    "grouped_text = df.groupby('인적사고')['재발방지대책 및 향후조치계획'].apply(lambda texts: ' '.join(texts))\n",
    "\n",
    "# 각 그룹에 대해 단어 빈도 계산\n",
    "result = {}\n",
    "for accident, text in grouped_text.items():\n",
    "    tokens = tokenize_korean(text)\n",
    "    freq = Counter(tokens)\n",
    "    # 빈도 상위 10개 단어 출력 (원하는 개수로 조정 가능)\n",
    "    common_words = freq.most_common(10)\n",
    "    result[accident] = common_words\n",
    "    print(f\"인적사고: {accident} - {sum(df['인적사고']==accident)}\")\n",
    "    print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_text = df.groupby('공종(중분류)')['재발방지대책 및 향후조치계획'].apply(lambda texts: ' '.join(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "# 한글 명사 추출을 위한 함수 정의 (필요에 따라 다른 토큰화 방법을 사용할 수 있음)\n",
    "def tokenize_korean(text):\n",
    "    return text.split()\n",
    "\n",
    "# '인적사고' 별로 '재발방지대책 및 향후조치계획' 텍스트를 하나로 합치기\n",
    "grouped_text = df.groupby('공종(중분류)')['재발방지대책 및 향후조치계획'].apply(lambda texts: ' '.join(texts))\n",
    "\n",
    "# 각 그룹에 대해 단어 빈도 계산\n",
    "result = {}\n",
    "for accident, text in grouped_text.items():\n",
    "    tokens = tokenize_korean(text)\n",
    "    freq = Counter(tokens)\n",
    "    # 빈도 상위 10개 단어 출력 (원하는 개수로 조정 가능)\n",
    "    common_words = freq.most_common(10)\n",
    "    result[accident] = common_words\n",
    "    print(f\"공종(중분류): {accident} - {sum(df['공종(중분류)']==accident)}\")\n",
    "    print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "# 한글 명사 추출을 위한 함수 정의 (필요에 따라 다른 토큰화 방법을 사용할 수 있음)\n",
    "def tokenize_korean(text):\n",
    "    return text.split()\n",
    "\n",
    "# '인적사고' 별로 '재발방지대책 및 향후조치계획' 텍스트를 하나로 합치기\n",
    "grouped_text = df.groupby('공사종류(중분류)')['재발방지대책 및 향후조치계획'].apply(lambda texts: ' '.join(texts))\n",
    "\n",
    "# 각 그룹에 대해 단어 빈도 계산\n",
    "result = {}\n",
    "for accident, text in grouped_text.items():\n",
    "    tokens = tokenize_korean(text)\n",
    "    freq = Counter(tokens)\n",
    "    # 빈도 상위 10개 단어 출력 (원하는 개수로 조정 가능)\n",
    "    common_words = freq.most_common(10)\n",
    "    result[accident] = common_words\n",
    "    print(f\"공사종류(중분류): {accident} - {sum(df['공사종류(중분류)']==accident)}\")\n",
    "    print(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긴 문자열이 잘리지 않도록 설정 (pandas 1.0 이상에서는 None 사용)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# 특정 조건에 맞는 데이터 추출 및 출력\n",
    "result = df[df['공종(중분류)'] == '통신설비공사']['재발방지대책 및 향후조치계획']\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
