{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['연도'] = df['발생일시'].str.slice(0, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['연도'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['연도'] == '2023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['인적사고'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('2023.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Embedding Vector 추출에 활용할 모델(jhgan/ko-sbert-sts) 불러오기\n",
    "model = SentenceTransformer('jhgan/ko-sbert-sts', use_auth_token=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('2023.csv')\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "sample = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = train.groupby(\"인적사고\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "cosine_res = []\n",
    "for name, group in tqdm(grouped):\n",
    "    plan = group[\"재발방지대책 및 향후조치계획\"]\n",
    "    vectors = np.stack(plan.apply(model.encode).to_numpy())\n",
    "    similarity = cosine_similarity(vectors, vectors)    \n",
    "    cosine_res += similarity[similarity.mean(axis=1).argmax()].tolist()\n",
    "    res[name] = plan.iloc[similarity.mean(axis=1).argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = cosine_res\n",
    "\n",
    "# 0.1 단위로 구간을 지정\n",
    "bins = np.arange(0, 1.1, 0.1)  # 0.0 ~ 1.0을 0.1 간격으로 나눔\n",
    "\n",
    "# 히스토그램 계산\n",
    "hist, bin_edges = np.histogram(arr, bins=bins)\n",
    "\n",
    "# 결과 출력\n",
    "for i in range(len(hist)):\n",
    "    print(f\"Range {bin_edges[i]:.1f} - {bin_edges[i+1]:.1f}: {hist[i]}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_v = {}\n",
    "for k,v in res.items():\n",
    "    res_v[k] = model.encode(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    accident = test.loc[i, \"인적사고\"]\n",
    "    sample.loc[i, \"재발방지대책 및 향후조치계획\"] = res[accident]\n",
    "    sample.iloc[i, 2:] = res_v[accident]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"대표문장.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "\n",
    "# 한국어 모델 다운로드 (최초 1회 실행)\n",
    "stanza.download('ko')\n",
    "\n",
    "# 한국어 파이프라인 구성: 토큰화, 품사 태깅, 의존 구문 분석 포함\n",
    "nlp = stanza.Pipeline('ko')\n",
    "\n",
    "# 분석할 문장 예시\n",
    "text = \"재발방지대책 및 향후조치계획에서 인적사고별 문구를 추출합니다.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "# 각 문장에 대해 의존 구문 구조 출력\n",
    "for sentence in doc.sentences:\n",
    "    for word in sentence.words:\n",
    "        print(f\"단어: {word.text}\\t의존관계: {word.deprel}\\t헤드 단어 인덱스: {word.head}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Embedding Vector 추출에 활용할 모델(jhgan/ko-sbert-sts) 불러오기\n",
    "model = SentenceTransformer('jhgan/ko-sbert-sts', use_auth_token=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플에 대한 Cosine Similarity 산식\n",
    "def cosine_similarity(a, b):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b) if norm_a != 0 and norm_b != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = '시스템 비계 발판 적재 하중 준수 및 안전교육 실시와 조치계획 이행 확인 통한 재발 방지 대책 및 향후 조치 계획.'\n",
    "s2 = ' TBM 시 사고사례 전파 및 작업전 안전교육 실시와 안전관리자 안전점검 실시를 통한 재발 방지 대책 및 향후 조치 계획'\n",
    "\n",
    "pred_embed = model.encode(s2)\n",
    "gt_embed = model.encode(s1)\n",
    "cosine_similarity(gt_embed,pred_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
