{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'C:/Users/minkyu/Desktop/dacon accident prevention'\n",
    "data_path= 'C:/Users/minkyu/Desktop/open/'\n",
    "train = pd.read_csv(data_path+\"train.csv\" )\n",
    "test = pd.read_csv(data_path+\"test.csv\" )\n",
    "sample = pd.read_csv(data_path+\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df.replace('-', np.nan, inplace=True)\n",
    "    df['공사종류(대분류)'] = df['공사종류'].str.split(' / ').str[0]\n",
    "    df['공사종류(중분류)'] = df['공사종류'].str.split(' / ').str[1]\n",
    "    df['공종(대분류)'] = df['공종'].str.split(' > ').str[0]\n",
    "    df['공종(중분류)'] = df['공종'].str.split(' > ').str[1]\n",
    "    df['사고객체(대분류)'] = df['사고객체'].str.split(' > ').str[0]\n",
    "    df['사고객체(중분류)'] = df['사고객체'].str.split(' > ').str[1]\n",
    "    df['사고인지 시간'] = df['사고인지 시간'].str.split('-').str[0].str.strip()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = preprocess(train)\n",
    "test = preprocess(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Embedding Vector 추출 모델을 GPU로 로드\n",
    "model = SentenceTransformer('jhgan/ko-sbert-sts', use_auth_token=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = train.groupby([\"공종(중분류)\", \"인적사고\"])\n",
    "\n",
    "res = {}\n",
    "cosine_res = []\n",
    "for name, group in tqdm(grouped):\n",
    "    plan = group[\"재발방지대책 및 향후조치계획\"]\n",
    "    \n",
    "    if len(plan) < 2:  # 데이터가 1개 이하라면 유사도 계산 불가\n",
    "        continue  \n",
    "\n",
    "    vectors = np.stack(plan.apply(model.encode).to_numpy())\n",
    "    similarity = cosine_similarity(vectors, vectors)    \n",
    "    \n",
    "    # 가장 평균 유사도가 높은 문장을 선택\n",
    "    best_idx = similarity.mean(axis=1).argmax()\n",
    "    cosine_res += similarity[best_idx].tolist()\n",
    "    res[name] = plan.iloc[best_idx]\n",
    "\n",
    "arr = cosine_res\n",
    "\n",
    "# 0.1 단위로 구간을 지정\n",
    "bins = np.arange(0, 1.1, 0.1)  # 0.0 ~ 1.0을 0.1 간격으로 나눔\n",
    "\n",
    "# 히스토그램 계산\n",
    "hist, bin_edges = np.histogram(arr, bins=bins)\n",
    "\n",
    "# 결과 출력\n",
    "for i in range(len(hist)):\n",
    "    print(f\"Range {bin_edges[i]:.1f} - {bin_edges[i+1]:.1f}: {hist[i]}개\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_v = {}\n",
    "for k,v in res.items():\n",
    "    res_v[k] = model.encode(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"baseline.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# sample 데이터프레임에 값 할당 (진행 상태 표시)\n",
    "for i in tqdm(range(len(test)), desc=\"Processing\", ncols=100):  # tqdm을 사용하여 진행 상태 표시\n",
    "    accident = test.loc[i, \"인적사고\"]  # 사고 유형\n",
    "    category = test.loc[i, \"공종(중분류)\"]  # 공종(중분류) 값\n",
    "\n",
    "    # (공종, 인적사고) 조합을 기준으로 res에서 재발방지대책을 가져옴\n",
    "    key = (category, accident)\n",
    "    if key in res:  # 해당 조합이 res에 존재하는 경우\n",
    "        sample.loc[i, \"재발방지대책 및 향후조치계획\"] = res[key]  # 문장 할당\n",
    "        \n",
    "        # 벡터 값도 가져와서 할당\n",
    "        vector = res_v[key]\n",
    "        sample.iloc[i, 2:2+len(vector)] = vector  # 벡터 길이에 맞게 할당\n",
    "        \n",
    "        # 진행 상황을 출력\n",
    "        if i % 100 == 0:  # 100번째마다 진행 상황 출력\n",
    "            print(f\"Processing {i}/{len(test)} - Accident: {accident}, Category: {category}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 문장\n",
    "sentence = \"안전사고 재발 방지를 위한 작업자 교육 및 안전보호구 착용 철저, 안전계단 설치 경사 재조정 및 안전교육 실시.\"\n",
    "\n",
    "# 문장의 임베딩 계산\n",
    "embedding = model.encode(sentence)\n",
    "\n",
    "# 결과 출력 (임베딩 벡터)\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.iloc[42, 2:2+len(vector)] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.iloc[160, 2:2+len(vector)]= embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(base_path+\"/rule_base_v2.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
