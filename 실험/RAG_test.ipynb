{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U bitsandbytes transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-gpu-cu12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/content/drive/MyDrive/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path+\"train.csv\" )\n",
    "test = pd.read_csv(data_path+\"test.csv\" )\n",
    "sample = pd.read_csv(data_path+\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df.replace('-', np.nan, inplace=True)\n",
    "    df['공사종류(대분류)'] = df['공사종류'].str.split(' / ').str[0]\n",
    "    df['공사종류(중분류)'] = df['공사종류'].str.split(' / ').str[1]\n",
    "    df['공종(대분류)'] = df['공종'].str.split(' > ').str[0]\n",
    "    df['공종(중분류)'] = df['공종'].str.split(' > ').str[1]\n",
    "    df['사고객체(대분류)'] = df['사고객체'].str.split(' > ').str[0]\n",
    "    df['사고객체(중분류)'] = df['사고객체'].str.split(' > ').str[1]\n",
    "    df['사고인지 시간'] = df['사고인지 시간'].str.split('-').str[0].str.strip()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train = preprocess(train)\n",
    "test = preprocess(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 통합 생성\n",
    "combined_training_data = train.apply(\n",
    "    lambda row: {\n",
    "        \"question\": (\n",
    "            f\"'{row['공사종류(중분류)']}' 공사 중 \"\n",
    "            f\"'{row['공종(중분류)']}' 작업에서 \"\n",
    "            f\"사고객체 '{row['사고객체(대분류)']}'(중분류: '{row['사고객체(중분류)']}')와 관련된 사고가 발생했습니다. \"\n",
    "            f\"작업 프로세스는 '{row['작업프로세스']}'이며, 사고 원인은 '{row['사고원인']}'입니다. \"\n",
    "            f\"재발 방지 대책 및 향후 조치 계획은 무엇인가요?\"\n",
    "        ),\n",
    "        \"answer\": row[\"재발방지대책 및 향후조치계획\"]\n",
    "    },\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# DataFrame으로 변환\n",
    "combined_training_data = pd.DataFrame(list(combined_training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 통합 생성\n",
    "combined_test_data = test.apply(\n",
    "    lambda row: {\n",
    "        \"question\": (\n",
    "            f\"'{row['공사종류(중분류)']}' 공사 중 \"\n",
    "            f\"'{row['공종(중분류)']}' 작업에서 \"\n",
    "            f\"사고객체 '{row['사고객체(대분류)']}'(중분류: '{row['사고객체(중분류)']}')와 관련된 사고가 발생했습니다. \"\n",
    "            f\"작업 프로세스는 '{row['작업프로세스']}'이며, 사고 원인은 '{row['사고원인']}'입니다. \"\n",
    "            f\"재발 방지 대책 및 향후 조치 계획은 무엇인가요?\"\n",
    "        )\n",
    "    },\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# DataFrame으로 변환\n",
    "combined_test_data = pd.DataFrame(list(combined_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpu 강제 버전\n",
    "model_id = \"NCSOFT/Llama-VARCO-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0}  # GPU 0번에 모델 전체를 강제로 올림\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Train 데이터 준비\n",
    "train_questions_prevention = combined_training_data['question'].tolist()\n",
    "train_answers_prevention = combined_training_data['answer'].tolist()\n",
    "\n",
    "train_documents = [\n",
    "    f\"Q: {q1}\\nA: {a1}\"\n",
    "    for q1, a1 in zip(train_questions_prevention, train_answers_prevention)\n",
    "]\n",
    "\n",
    "# 임베딩 생성\n",
    "embedding_model_name = \"jhgan/ko-sbert-nli\"\n",
    "embedding = HuggingFaceEmbeddings(model_name=embedding_model_name)\n",
    "\n",
    "# 벡터 스토어에 문서 추가\n",
    "vector_store = FAISS.from_texts(train_documents, embedding)\n",
    "\n",
    "# Retriever 정의\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})\n",
    "\n",
    "text_generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=True,\n",
    "    temperature=0.1,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=64,\n",
    "    batch_size=16  # 배치 크기 지정 (GPU 메모리에 맞게 조정)\n",
    ")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "### 지침: 당신은 건설 안전 전문가입니다.\n",
    "질문에 대한 답변을 핵심 내용만 요약하여 간략하게 작성하세요.\n",
    "- 서론, 배경 설명 또는 추가 설명을 절대 포함하지 마세요.\n",
    "- 다음과 같은 조치를 취할 것을 제안합니다: 와 같은 내용을 포함하지 마세요.\n",
    "\n",
    "{context}\n",
    "\n",
    "### 질문:\n",
    "{question}\n",
    "\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n",
    "# 커스텀 프롬프트 생성\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# RAG 체인 생성\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터 준비\n",
    "test_questions = combined_test_data['question'].tolist()\n",
    "batch_size = 32  # GPU 메모리에 맞게 조정\n",
    "\n",
    "test_results = []\n",
    "print(\"테스트 실행 시작... 총 테스트 샘플 수:\", len(test_questions))\n",
    "\n",
    "# 배치 단위로 처리\n",
    "for i in tqdm(range(0, len(test_questions), batch_size), desc=\"처리 진행률\"):\n",
    "    batch_questions = test_questions[i:i + batch_size]\n",
    "\n",
    "    # 배치로 문서 검색\n",
    "    docs_batch = retriever.batch(batch_questions)  # 배치로 문서 검색\n",
    "\n",
    "    # 검색된 문서에서 답변 추출\n",
    "    for docs in docs_batch:\n",
    "        # 문서 1개만 가져오므로 docs[0]의 답변 부분을 추출\n",
    "        answer = docs[0].page_content.split(\"A: \")[1]  # \"Q: 질문\\nA: 답변\" 형식 가정\n",
    "        test_results.append(answer)\n",
    "\n",
    "print(\"\\n테스트 실행 완료! 총 결과 수:\", len(test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model_name = \"jhgan/ko-sbert-sts\"\n",
    "embedding = SentenceTransformer(embedding_model_name)\n",
    "\n",
    "# 문장 리스트를 입력하여 임베딩 생성\n",
    "pred_embeddings = embedding.encode(test_results)\n",
    "print(pred_embeddings.shape)  # (샘플 개수, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(data_path+\"sample_submission.csv\", encoding = 'utf-8-sig')\n",
    "# 최종 결과 저장\n",
    "submission.iloc[:,1] = test_results\n",
    "submission.iloc[:,2:] = pred_embeddings\n",
    "submission.head()\n",
    "\n",
    "# 최종 결과를 CSV로 저장\n",
    "submission.to_csv('submissionv2.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
