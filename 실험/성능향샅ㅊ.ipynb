{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_community\n",
    "!pip install pypdfium2\n",
    "!pip install langchain_experimental\n",
    "!pip install kiwipiepy\n",
    "!pip install faiss-gpu-cu12\n",
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "root_folder = \"C:/Users/minkyu/Desktop/dacon accident prevention/진짜 시작/건설안전지침_md\"\n",
    "\n",
    "all_documents = []  # Document 객체 리스트\n",
    "\n",
    "# 폴더를 순회하며 .md 파일 처리\n",
    "for current_path, dirs, files in os.walk(root_folder):\n",
    "    # 현재 경로가 루트 폴더와 다른 경우(=서브폴더), 폴더명을 메타데이터 title로 사용\n",
    "    if current_path != root_folder:\n",
    "        folder_title = os.path.basename(current_path)\n",
    "    else:\n",
    "        folder_title = \"\"\n",
    "\n",
    "    # 현재 폴더의 .md 파일 목록\n",
    "    md_files = [f for f in files if f.lower().endswith('.md')]\n",
    "\n",
    "    # page 번호를 추출해 정렬하기 위한 헬퍼 함수\n",
    "    def extract_page_number(filename):\n",
    "        # 예: \"page_1.md\" -> \"page_1\" -> 뒤의 \"1\" -> int(1)\n",
    "        base = os.path.splitext(filename)[0]  # \"page_1\"\n",
    "        return int(base.split('_')[-1])       # \"1\"\n",
    "\n",
    "    # .md 파일 정렬\n",
    "    md_files = sorted(md_files, key=extract_page_number)\n",
    "\n",
    "    # 첫 3개(page_1, page_2, page_3)는 무시하고, 그 이후 파일들만\n",
    "    md_files_to_read = md_files[3:]\n",
    "\n",
    "    # 페이지 단위로 Document 생성\n",
    "    for i, md_file in enumerate(md_files_to_read, start=4):  # 시작 인덱스를 4로 설정\n",
    "        md_file_path = os.path.join(current_path, md_file)\n",
    "        with open(md_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            page_content = f.read()\n",
    "\n",
    "        # 메타데이터에 폴더명과 실제 페이지 번호(i)를 저장\n",
    "        doc_metadata = {\n",
    "            \"title\": folder_title if folder_title else \"NoTitle\",\n",
    "            \"page_num\": i\n",
    "        }\n",
    "\n",
    "        doc = Document(page_content=page_content, metadata=doc_metadata)\n",
    "        all_documents.append(doc)\n",
    "\n",
    "        print(f\"폴더: {folder_title}, 파일: {md_file}, 페이지 번호: {i}\")\n",
    "\n",
    "print(f\"\\n총 Document 수: {len(all_documents)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sbert-sts\")\n",
    "\n",
    "content_index = FAISS.from_documents(all_documents, embeddings)\n",
    "content_index.save_local(\"faiss_content_index\")\n",
    "\n",
    "print(\"FAISS content index saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_dataset = pd.read_csv('train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_training_data = train_dataset.apply(\n",
    "    lambda row: {\n",
    "        \"text\": (\n",
    "            f\"{row['인적사고']} 에 대한 안전조치사항 \"\n",
    "        ),\n",
    "        \"answer\": row[\"재발방지대책 및 향후조치계획\"]\n",
    "    },\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_training_data[0]['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bm25 토크나이저로 한국어 토크나이저 사용 하기 위해서 불러옴\n",
    "from kiwipiepy import Kiwi\n",
    "kiwi = Kiwi()\n",
    "\n",
    "def ko_kiwi_tokenizer(text: str):\n",
    "    # Kiwi 토크나이저는 각 토큰에 대한 다양한 정보를 반환합니다.\n",
    "    # 여기서는 토큰의 표면 형태(텍스트)만 추출합니다.\n",
    "    tokens = kiwi.tokenize(text)\n",
    "    return [token[0] for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain.docstore.document import Document\n",
    "# Retriever 정의\n",
    "# pdf_chunks에서 Document 객체 리스트 생성\n",
    "# pdf_chunks에서 Document 객체 리스트 생성\n",
    "docs = all_documents\n",
    "retriever = content_index.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "bm25_retriever = BM25Retriever.from_documents(docs, tokenizer=ko_kiwi_tokenizer , k =3 )\n",
    "\n",
    "# 앙상블 리트리버 생성\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, retriever],\n",
    "    weights=[0.5, 0.5]  # 각 리트리버에 동일 가중치 부여 (가중치 합은 1.0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_training_data[1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=9\n",
    "\n",
    "# query와 정답 출력\n",
    "query = combined_training_data[n]['text']\n",
    "print('질문 :', query)\n",
    "print('정답 :', combined_training_data[n]['answer'])\n",
    "\n",
    "# query 임베딩 계산\n",
    "query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "# 앙상블 리트리버로 검색 후 각 문서에 대해 코사인 유사도 계산 및 출력\n",
    "results = ensemble_retriever.get_relevant_documents(query)\n",
    "\n",
    "for doc in results:\n",
    "    # 문서의 내용을 일부 출력\n",
    "    \n",
    "    # 문서 임베딩 계산 (문서 전체를 대상으로 임베딩을 생성합니다)\n",
    "    doc_embedding = embeddings.embed_query(doc.page_content)\n",
    "    similarity = cosine_similarity(query_embedding, doc_embedding)\n",
    "    \n",
    "    print(f\"\\n제목: {doc.metadata.get('title')}\")\n",
    "    print(\"내용 일부:\", doc.page_content)\n",
    "    print(\"코사인 유사도:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
