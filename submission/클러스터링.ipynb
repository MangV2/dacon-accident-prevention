{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 디바이스 설정 (GPU 사용 가능 시 GPU 사용)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"사용하는 디바이스:\", device)\n",
    "\n",
    "# 1. 데이터 로딩 및 전처리\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "texts = df[\"재발방지대책 및 향후조치계획\"].dropna().tolist()\n",
    "\n",
    "# 2. 문장 임베딩 (Hugging Face의 ko-sBERT 모델 사용)\n",
    "model_name = \"jhgan/ko-sbert-sts\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model = model.to(device)\n",
    "model.eval()  # 평가 모드로 전환\n",
    "\n",
    "def embed_text(text):\n",
    "    # 입력 생성 후, 딕셔너리 내 모든 텐서를 GPU로 이동\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # outputs.last_hidden_state 또는 outputs[0] 사용 (모델에 따라 다름)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "    return embeddings.squeeze().cpu().numpy()  # 결과는 CPU로 다시 이동\n",
    "\n",
    "print(\"문장 임베딩 생성 중...\")\n",
    "embeddings = np.array([embed_text(text) for text in tqdm(texts)])\n",
    "\n",
    "# 3. 클러스터링 (K-means 예시)\n",
    "n_clusters = 5  # 군집 수는 도메인에 맞게 조정\n",
    "print(\"클러스터링 진행 중...\")\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "df['cluster'] = clusters\n",
    "\n",
    "# 4. 군집 해석: 각 클러스터별 대표 문장 추출 (유사도 기준 Top 5)\n",
    "def get_top5_representative_texts(cluster_id):\n",
    "    cluster_texts = df[df['cluster'] == cluster_id][\"재발방지대책 및 향후조치계획\"].tolist()\n",
    "    cluster_embeddings = np.array([embed_text(t) for t in cluster_texts])\n",
    "    centroid = cluster_embeddings.mean(axis=0)\n",
    "    norms = np.linalg.norm(cluster_embeddings, axis=1) * np.linalg.norm(centroid)\n",
    "    similarities = np.dot(cluster_embeddings, centroid) / (norms + 1e-8)\n",
    "    top5_idx = similarities.argsort()[-5:][::-1]\n",
    "    top5_texts = [cluster_texts[idx] for idx in top5_idx]\n",
    "    return top5_texts\n",
    "\n",
    "print(\"군집별 대표 문장(상위 5개) 추출 중...\")\n",
    "for i in tqdm(range(n_clusters)):\n",
    "    top5_texts = get_top5_representative_texts(i)\n",
    "    print(f\"\\nCluster {i} 대표 문장 Top 5:\")\n",
    "    for j, text in enumerate(top5_texts, 1):\n",
    "        print(f\"{j}. {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "print(\"UMAP 시각화 중...\")\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "embedding_2d = reducer.fit_transform(embeddings)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(embedding_2d[:, 0], embedding_2d[:, 1], c=clusters, cmap='viridis', s=5)\n",
    "plt.title(\"UMAP을 활용한 군집 시각화\")\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# k 범위를 지정하여 최적의 k값을 찾는 예시\n",
    "silhouette_scores = {}\n",
    "for k in range(8, 21):  # k=2부터 10까지 테스트\n",
    "    kmeans_temp = KMeans(n_clusters=k, random_state=42)\n",
    "    clusters_temp = kmeans_temp.fit_predict(embeddings)\n",
    "    score = silhouette_score(embeddings, clusters_temp)\n",
    "    silhouette_scores[k] = score\n",
    "    print(f\"k = {k}, Silhouette Score = {score:.4f}\")\n",
    "\n",
    "# 최적의 k값 선택 (silhouette score 최대)\n",
    "optimal_k = max(silhouette_scores, key=silhouette_scores.get)\n",
    "print(f\"\\n최적의 k값: {optimal_k}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# k 범위를 지정하여 최적의 k값을 찾는 예시\n",
    "silhouette_scores = {}\n",
    "for k in range(21, 50):  # k=2부터 10까지 테스트\n",
    "    kmeans_temp = KMeans(n_clusters=k, random_state=42)\n",
    "    clusters_temp = kmeans_temp.fit_predict(embeddings)\n",
    "    score = silhouette_score(embeddings, clusters_temp)\n",
    "    silhouette_scores[k] = score\n",
    "    print(f\"k = {k}, Silhouette Score = {score:.4f}\")\n",
    "\n",
    "# 최적의 k값 선택 (silhouette score 최대)\n",
    "optimal_k = max(silhouette_scores, key=silhouette_scores.get)\n",
    "print(f\"\\n최적의 k값: {optimal_k}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "def visualize_clustering(embeddings, k):\n",
    "    # k값에 따른 클러스터링 수행\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    clusters_k = kmeans.fit_predict(embeddings)\n",
    "    \n",
    "    # UMAP을 이용하여 2차원으로 차원 축소\n",
    "    reducer = umap.UMAP(random_state=42)\n",
    "    embedding_2d = reducer.fit_transform(embeddings)\n",
    "    \n",
    "    # 시각화\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(embedding_2d[:, 0], embedding_2d[:, 1], c=clusters_k, cmap='viridis', s=5)\n",
    "    plt.title(f\"UMAP 시각화 - k = {k}\")\n",
    "    plt.xlabel(\"UMAP 1\")\n",
    "    plt.ylabel(\"UMAP 2\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"k=19일 때 시각화 진행 중...\")\n",
    "visualize_clustering(embeddings, k=19)\n",
    "\n",
    "print(\"k=24일 때 시각화 진행 중...\")\n",
    "visualize_clustering(embeddings, k=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
